{
    "GPT": 
    {
        "chatgpt-4o-latest":
        {
            "label": "OpenAI's ChatGPT-4o points to the GPT-4o snapshot currently used in ChatGPT. GPT-4o is their versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs. It is the best model for most tasks, and is their most capable model outside of their o-series models.",
            "max_token": 16384,
            "context_token": 128000,
            "data": "Up to Sep 2023",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4o"
            }
        },


        "gemini-1.5-flash":
        {
            "label": "Google's fast and versatile performance across a diverse variety of tasks",
            "max_token": 8000,
            "context_token": 1000000,
            "data": "Latest update: Sep 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-1.5-flash"
            }
        },

        "gemini-1.5-flash-8b":
        {
            "label": "Google's fast and versatile performance across a diverse variety of tasks",
            "max_token": 8000,
            "context_token": 1000000,
            "data": "Latest update: Oct 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-1.5-flash-8b"
            }
        },

        "gemini-1.5-pro":
        {
            "label": "Google model for complex reasoning tasks requiring more intelligence",
            "max_token": 8000,
            "context_token": 2000000,
            "data": "Latest update: Sep 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-1.5-pro"
            }
        },

        "gemini-2.0-flash":
        {
            "label": "Google model with next generation features, speed, and multimodal generation for a diverse variety of tasks",
            "max_token": 8000,
            "context_token": 1000000,
            "data": "Latest update: Feb 2025, Knowledge cutoff: Aug 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash"
            }
        },

        "gemini-2.0-flash-lite":
        {
            "label": "Google model that reasons over the most complex problems, Show the thinking process of the model, Tackle difficult code and math problems",
            "max_token": 8000,
            "context_token": 1000000,
            "data": "Latest update: Feb 2025, Knowledge cutoff: Aug 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash-lite"
            }
        },

        "gemini-2.5-flash":
        {
            "label": "Google's best model in terms of price-performance, offering well-rounded capabilities. Gemini 2.5 Flash rate limits are more restricted since it is an experimental / preview model",
            "max_token": 65000,
            "context_token": 1000000,
            "data": "Latest update: Jun 2025, Knowledge cutoff: Jan 2025",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash"
            }
        },

        "gemini-2.5-flash-lite-preview-06-17":
        {
            "label": "Google's Gemini 2.5 Flash model optimized for cost efficiency and low latency.",
            "max_token": 65000,
            "context_token": 1000000,
            "data": "Latest update: Jun 2025, Knowledge cutoff: Jan 2025",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite"
            }
        },

        "gemini-2.5-pro":
        {
            "label": "Google's state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.",
            "max_token": 65000,
            "context_token": 1000000,
            "data": "Latest update: Mar 2025, Knowledge cutoff: Jan 2025",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "GoogleAI",
                "apikey-env": "GEMINI_API_KEY",
                "apiurl": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "model_url": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5"
            }
        },


        "gpt-4.1":
        {
            "label": "OpenAI's flagship model for complex tasks. It is well suited for problem solving across domains.",
            "max_token": 32000,
            "context_token": 1000000,
            "data": "Up to May 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4.1"
            }
        },

        "gpt-4.1-mini":
        {
            "label": "OpenAI's GPT-4.1 mini provides a balance between intelligence, speed, and cost that makes it an attractive model for many use cases.",
            "max_token": 32000,
            "context_token": 1000000,
            "data": "Up to May 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4.1-mini"
            }
        },

        "gpt-4.1-nano":
        {
            "label": "OpenAI's GPT-4.1 nano is the fastest, most cost-effective GPT-4.1 model.",
            "max_token": 32000,
            "context_token": 1000000,
            "data": "Up to May 2024",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4.1-nano"
            }
        },

        "gpt-4o":
        {
            "label": "OpenAI's GPT-4o (“o” for “omni”) is their versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is their most capable model outside of their o-series models.",
            "max_token": 16384,
            "context_token": 128000,
            "data": "Up to Sep 2023",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4o"
            }
        },

        "gpt-4o-mini":
        {
            "label": "OpenAI's GPT-4o mini (“o” for “omni”) is a fast, affordable small model for focused tasks. It accepts both text and image inputs, and produces text outputs (including Structured Outputs).",
            "max_token": 16384,
            "context_token": 128000,
            "data": "Up to Sep 2023",
            "status": "active",
            "status_details": "",
            "capability": ["vision"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4o-mini"
            }
        },

        "gpt-4o-mini-search-preview":
        {
            "label": "OpenAI's GPT-4o mini Search Preview is a specialized model trained to understand and execute web search queries with the Chat Completions API. In addition to token fees, web search queries have a fee per tool call..",
            "max_token": 16384,
            "context_token": 128000,
            "data": "Up to Oct 2023",
            "status": "active",
            "status_details": "",
            "capability": ["websearch"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4o-mini-search-preview"
            }
        },

        "gpt-4o-search-preview":
        {
            "label": "OpenAI's GPT-4o Search Preview is a specialized model trained to understand and execute web search queries with the Chat Completions API. In addition to token fees, web search queries have a fee per tool call..",
            "max_token": 16384,
            "context_token": 128000,
            "data": "Up to Oct 2023",
            "status": "active",
            "status_details": "",
            "capability": ["websearch"],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models/gpt-4o-search-preview"
            }
        },


        "o3":
        {
            "label": "OpenAI's o3 is a well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. It also excels at technical writing and instruction-following. Use it to think through multi-step problems that involve analysis across text, code, and images.",
            "max_token": 100000,
            "context_token": 208000,
            "data": "Up to May 2024",
            "status": "active",
            "status_details": "beta",
            "capability": [],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "beta_model": true,
                "removed_roles": ["system"],
                "disabled_features": ["temperature", "preset"],
                "model_url": "https://platform.openai.com/docs/models/o3"
            }
        },

        "o3-mini":
        {
            "label": "OpenAI's o3-mini is their newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini.",
            "max_token": 100000,
            "context_token": 208000,
            "data": "Up to Sep 2023",
            "status": "active",
            "status_details": "beta",
            "capability": [],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "beta_model": true,
                "removed_roles": ["system"],
                "disabled_features": ["temperature", "preset"],
                "model_url": "https://platform.openai.com/docs/models/o3-mini"
            }
        },

        "o3-pro":
        {
            "label": "OpenAI's Version of o3 with more compute for better responses",
            "max_token": 100000,
            "context_token": 208000,
            "data": "Up to May 2024",
            "status": "active",
            "status_details": "beta",
            "capability": [],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "beta_model": true,
                "removed_roles": ["system"],
                "disabled_features": ["temperature", "preset"],
                "model_url": "https://platform.openai.com/docs/models/o3-mini"
            }
        },

        "o4-mini":
        {
            "label": "OpenAI's o4-mini is their latest small o-series model. It's optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks.",
            "max_token": 100000,
            "context_token": 208000,
            "data": "Up to May 2024",
            "status": "active",
            "status_details": "beta",
            "capability": [],
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "beta_model": true,
                "removed_roles": ["system"],
                "disabled_features": ["temperature", "preset"],
                "model_url": "https://platform.openai.com/docs/models/o4-mini"
            }
        },


        "r1-1776":
        {
            "label": "Perplexity's offline AI model that provides uncensored, unbiased responses without relying on real-time search.",
            "max_token": 4096,
            "context_token": 127000,
            "data": "Perplexity model",
            "status": "active",
            "status_details": "",
            "capability": [],
            "meta": {
                "provider": "PerplexityAI",
                "apikey-env": "PERPLEXITY_API_KEY",
                "apiurl": "https://api.perplexity.ai",
                "msg_format": "role_content",
                "init_msg": {"role": "system", "content": "You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user." },
                "disabled_features": ["role", "prompt_preset", "preset"],
                "model_url": "https://docs.perplexity.ai/models/models/r1-1776"
            }
        },


        "sonar":
        {
            "label": "Perplexity's lightweight offering with search grounding, quicker and cheaper than Sonar Pro",
            "max_token": 4096,
            "context_token": 127000,
            "data": "Perplexity model",
            "status": "active",
            "status_details": "",
            "capability": [],
            "meta": {
                "provider": "PerplexityAI",
                "apikey-env": "PERPLEXITY_API_KEY",
                "apiurl": "https://api.perplexity.ai",
                "msg_format": "role_content",
                "init_msg": {"role": "system", "content": "You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user.", "oaiwui_skip": "" },
                "disabled_features": ["role", "prompt_preset", "preset"],
                "model_url": "https://docs.perplexity.ai/models/models/sonar"
            }
        },

        "sonar-deep-research":
        {
            "label": "Perplexity's premier search offering outputs CoT in its response as well with search grounding, supporting advanced queries and follow-ups.",
            "max_token": 4096,
            "context_token": 60000,
            "data": "Perplexity model",
            "status": "active",
            "status_details": "",
            "capability": [],
            "meta": {
                "provider": "PerplexityAI",
                "apikey-env": "PERPLEXITY_API_KEY",
                "apiurl": "https://api.perplexity.ai",
                "msg_format": "role_content",
                "init_msg": {"role": "system", "content": "You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user." },
                "disabled_features": ["role", "prompt_preset", "preset"],
                "model_url": "https://docs.perplexity.ai/models/models/sonar-deep-research"
            }
        },

        "sonar-pro":
        {
            "label": "Perplexity's premier search offering with search grounding, supporting advanced queries and follow-ups.",
            "max_token": 8192,
            "context_token": 200000,
            "data": "Perplexity model",
            "status": "active",
            "status_details": "",
            "capability": [],
            "meta": {
                "provider": "PerplexityAI",
                "apikey-env": "PERPLEXITY_API_KEY",
                "apiurl": "https://api.perplexity.ai",
                "msg_format": "role_content",
                "init_msg": {"role": "system", "content": "You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user." },
                "disabled_features": ["role", "prompt_preset", "preset"],
                "model_url": "https://docs.perplexity.ai/models/models/sonar-pro"
            }
        },

        "sonar-reasoning":
        {
            "label": "Perplexity's premier search offering outputs Chain-of-Thought (CoT) in its response as well.",
            "max_token": 4096,
            "context_token": 127000,
            "data": "Perplexity model",
            "status": "active",
            "status_details": "",
            "capability": [],
            "meta": {
                "provider": "PerplexityAI",
                "apikey-env": "PERPLEXITY_API_KEY",
                "apiurl": "https://api.perplexity.ai",
                "msg_format": "role_content",
                "init_msg": {"role": "system", "content": "You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user." },
                "disabled_features": ["role", "prompt_preset", "preset"],
                "model_url": "https://docs.perplexity.ai/models/models/sonar-reasoning"
            }
        },

        "sonar-reasoning-pro":
        {
            "label": "Perplexity's premier search offering leveraging advanced multi-step Chain-of-Thought (CoT) in its response as well with search grounding, supporting advanced queries and follow-ups.",
            "max_token": 8192,
            "context_token": 127000,
            "data": "Perplexity model",
            "status": "active",
            "status_details": "",
            "capability": [],
            "meta": {
                "provider": "PerplexityAI",
                "apikey-env": "PERPLEXITY_API_KEY",
                "apiurl": "https://api.perplexity.ai",
                "msg_format": "role_content",
                "init_msg": {"role": "system", "content": "You are an artificial intelligence assistant and you need to engage in a helpful, detailed, polite conversation with a user." },
                "disabled_features": ["role", "prompt_preset", "preset"],
                "model_url": "https://docs.perplexity.ai/models/models/sonar-reasoning-pro"
            }
        }
    },
    "Image":
    {
        "dall-e-2":
        {
            "label": "The previous DALL·E model released in Nov 2022. The maximum prompt length is 1000 characters.",
            "image_size": ["256x256", "512x512", "1024x1024"],
            "max_prompt_length": 1000,
            "status": "active",
            "status_details": "",
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models#dall-e"
            }
        },

        "dall-e-3":
        {
            "label": "The latest DALL·E model released in Nov 2023. The maximum prompt length is 4000 characters.",
            "image_size": ["1024x1024", "1024x1792", "1792x1024"],
            "max_prompt_length": 4000,
            "status": "active",
            "status_details": "",
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models#dall-e",
                "quality": ["standard", "hd"],
                "style": ["vivid", "natural"]
            }
        },

        "gpt-image-1":
        {
            "label": "OpenAI's GPT Image 1 is their new state-of-the-art image generation model.",
            "image_size": ["auto", "1024x1024", "1536x1024", "1024x1536"],
            "max_prompt_length": 1000,
            "status": "active",
            "status_details": "",
            "meta": {
                "provider": "OpenAI",
                "apikey-env": "OPENAI_API_KEY",
                "model_url": "https://platform.openai.com/docs/models#dall-e",
                "quality": ["auto", "low", "medium", "high"],
                "transparent": true
            }
        }


    }
}
