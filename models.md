| Mode | Model | Provider | Status | Capability | Notes | About |
| --- | --- | --- | --- | --- | --- | --- |
| GPT | [`ollama`](https://ollama.com/) | SelfHosted | active | vision`?` | | Self-hosted models using [`ollama`](https://ollama.com/); will search for `OLLAMA_HOST` environment variable |
| GPT | [`chatgpt-4o-latest`](https://platform.openai.com/docs/models/gpt-4o) | OpenAI | active | vision |  | OpenAI's ChatGPT-4o points to the GPT-4o snapshot currently used in ChatGPT. GPT-4o is their versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs. It is the best model for most tasks, and is their most capable model outside of their o-series models. |
| GPT | [`gemini-1.5-flash`](https://ai.google.dev/gemini-api/docs/models#gemini-1.5-flash) | GoogleAI | active | vision |  | Google's fast and versatile performance across a diverse variety of tasks |
| GPT | [`gemini-1.5-flash-8b`](https://ai.google.dev/gemini-api/docs/models#gemini-1.5-flash-8b) | GoogleAI | active | vision |  | Google's fast and versatile performance across a diverse variety of tasks |
| GPT | [`gemini-1.5-pro`](https://ai.google.dev/gemini-api/docs/models#gemini-1.5-pro) | GoogleAI | active | vision |  | Google model for complex reasoning tasks requiring more intelligence |
| GPT | [`gemini-2.0-flash`](https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash) | GoogleAI | active | vision |  | Google model with next generation features, speed, and multimodal generation for a diverse variety of tasks |
| GPT | [`gemini-2.0-flash-lite`](https://ai.google.dev/gemini-api/docs/models#gemini-2.0-flash-lite) | GoogleAI | active | vision |  | Google model that reasons over the most complex problems, Show the thinking process of the model, Tackle difficult code and math problems |
| GPT | [`gemini-2.5-flash-preview-04-17`](https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview) | GoogleAI | active | vision |  | Google's best model in terms of price-performance, offering well-rounded capabilities. Gemini 2.5 Flash rate limits are more restricted since it is an experimental / preview model |
| GPT | [`gemini-2.5-pro-preview-03-25`](https://ai.google.dev/gemini-api/docs/models#gemini-2.5-pro-preview-03-25) | GoogleAI | active | vision |  | Google's state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context. |
| GPT | [`gpt-4.1`](https://platform.openai.com/docs/models/gpt-4.1) | OpenAI | active | vision |  | OpenAI's flagship model for complex tasks. It is well suited for problem solving across domains. |
| GPT | [`gpt-4.1-mini`](https://platform.openai.com/docs/models/gpt-4.1-mini) | OpenAI | active | vision |  | OpenAI's GPT-4.1 mini provides a balance between intelligence, speed, and cost that makes it an attractive model for many use cases. |
| GPT | [`gpt-4.1-nano`](https://platform.openai.com/docs/models/gpt-4.1-nano) | OpenAI | active | vision |  | OpenAI's GPT-4.1 nano is the fastest, most cost-effective GPT-4.1 model. |
| GPT | [`gpt-4o`](https://platform.openai.com/docs/models/gpt-4o) | OpenAI | active | vision |  | OpenAI's GPT-4o (“o” for “omni”) is their versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is their most capable model outside of their o-series models. |
| GPT | [`gpt-4o-mini`](https://platform.openai.com/docs/models/gpt-4o-mini) | OpenAI | active | vision |  | OpenAI's GPT-4o mini (“o” for “omni”) is a fast, affordable small model for focused tasks. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). |
| GPT | [`gpt-4o-mini-search-preview`](https://platform.openai.com/docs/models/gpt-4o-mini-search-preview) | OpenAI | active | websearch |  | OpenAI's GPT-4o mini Search Preview is a specialized model trained to understand and execute web search queries with the Chat Completions API. In addition to token fees, web search queries have a fee per tool call.. |
| GPT | [`gpt-4o-search-preview`](https://platform.openai.com/docs/models/gpt-4o-search-preview) | OpenAI | active | websearch |  | OpenAI's GPT-4o Search Preview is a specialized model trained to understand and execute web search queries with the Chat Completions API. In addition to token fees, web search queries have a fee per tool call.. |
| GPT | [`o3`](https://platform.openai.com/docs/models/o3) | OpenAI | active |  | beta | OpenAI's o3 is a well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. It also excels at technical writing and instruction-following. Use it to think through multi-step problems that involve analysis across text, code, and images. |
| GPT | [`o3-mini`](https://platform.openai.com/docs/models/o3-mini) | OpenAI | active |  | beta | OpenAI's o3-mini is their newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. |
| GPT | [`o4-mini`](https://platform.openai.com/docs/models/o4-mini) | OpenAI | active |  | beta | OpenAI's o4-mini is their latest small o-series model. It's optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. |
| GPT | [`r1-1776`](https://docs.perplexity.ai/models/models/r1-1776) | PerplexityAI | active |  |  | Perplexity's offline AI model that provides uncensored, unbiased responses without relying on real-time search. |
| GPT | [`sonar`](https://docs.perplexity.ai/models/models/sonar) | PerplexityAI | active |  |  | Perplexity's lightweight offering with search grounding, quicker and cheaper than Sonar Pro |
| GPT | [`sonar-deep-research`](https://docs.perplexity.ai/models/models/sonar-deep-research) | PerplexityAI | active |  |  | Perplexity's premier search offering outputs CoT in its response as well with search grounding, supporting advanced queries and follow-ups. |
| GPT | [`sonar-pro`](https://docs.perplexity.ai/models/models/sonar-pro) | PerplexityAI | active |  |  | Perplexity's premier search offering with search grounding, supporting advanced queries and follow-ups. |
| GPT | [`sonar-reasoning`](https://docs.perplexity.ai/models/models/sonar-reasoning) | PerplexityAI | active |  |  | Perplexity's premier search offering outputs Chain-of-Thought (CoT) in its response as well. |
| GPT | [`sonar-reasoning-pro`](https://docs.perplexity.ai/models/models/sonar-reasoning-pro) | PerplexityAI | active |  |  | Perplexity's premier search offering leveraging advanced multi-step Chain-of-Thought (CoT) in its response as well with search grounding, supporting advanced queries and follow-ups. |
| Image | [`dall-e-2`](https://platform.openai.com/docs/models#dall-e) | OpenAI | active |  |  | The previous DALL·E model released in Nov 2022. The maximum prompt length is 1000 characters. |
| Image | [`dall-e-3`](https://platform.openai.com/docs/models#dall-e) | OpenAI | active |  |  | The latest DALL·E model released in Nov 2023. The maximum prompt length is 4000 characters. |
| Image | [`gpt-image-1`](https://platform.openai.com/docs/models#dall-e) | OpenAI | active |  |  | OpenAI's GPT Image 1 is their new state-of-the-art image generation model. |
